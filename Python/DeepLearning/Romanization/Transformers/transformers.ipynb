{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Romanization using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 21:30:28.699643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 21:30:28.736399: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from hangul_utils import split_syllables, join_jamos\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 21:30:29.548308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:29.563871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:29.564000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kor_syllable.pkl\", \"rb\") as f:\n",
    "    kr_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eng_syllable.pkl\", \"rb\") as f:\n",
    "    en_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86191"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86191"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices for kor character\n",
    "temp_dict_kr = {}\n",
    "temp_dict_kr[\"<sos>\"] = 0 # Not used for now\n",
    "temp_dict_kr[\"<eos>\"] = 0 # Not used for now\n",
    "for string in kr_list:\n",
    "    for char in string:\n",
    "        temp_dict_kr[char] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices for eng character\n",
    "temp_dict_en = {}\n",
    "temp_dict_en[\"<sos>\"] = 0 # Not used for now\n",
    "temp_dict_en[\"<eos>\"] = 0 # Not used for now\n",
    "temp_dict_en[\"-\"] = 0\n",
    "for string in en_list:\n",
    "    for char in string:\n",
    "        temp_dict_en[char] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_dict_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_dict_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict_kr = {}\n",
    "key_list = list(temp_dict_kr.keys())\n",
    "for i in range(len(temp_dict_kr)):\n",
    "    indices_dict_kr[key_list[i]] = i+1 # 0th index for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_dict_kr[\"<sos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_dict_kr[\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict_en = {}\n",
    "key_list = list(temp_dict_en.keys())\n",
    "for i in range(len(temp_dict_en)):\n",
    "    indices_dict_en[key_list[i]] = i+1 # 0th index for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_dict_en[\"<sos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory management:\n",
    "kr_list = kr_list[0:len(kr_list)//7]\n",
    "en_list = en_list[0:len(en_list)//7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12313"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_idx(string, indices_dict):\n",
    "    index_list = []\n",
    "    index_list.append(1) #<sos> append by default\n",
    "    for char in string:\n",
    "        index_list.append(indices_dict[char])\n",
    "    index_list.append(2) #<eos> append by default\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 6, 7, 5, 7, 8, 9, 10, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx(kr_list[0], indices_dict_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_dict_kr = {}\n",
    "for key in indices_dict_kr.keys():\n",
    "    reversed_dict_kr[indices_dict_kr[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_dict_en = {}\n",
    "for key in indices_dict_en.keys():\n",
    "    reversed_dict_en[indices_dict_en[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idxlist_to_char(idxlist, reversed_dict):\n",
    "    result_list = []\n",
    "    for idx in idxlist:\n",
    "        if idx == 0: # padding idx\n",
    "            break\n",
    "        result_list.append(reversed_dict[int(idx)])\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'ㅈ', 'ㅓ', 'ㄴ', 'ㄹ', 'ㅏ', 'ㄴ', 'ㅏ', 'ㅁ', 'ㄷ', 'ㅗ', '<eos>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxlist_to_char(char_to_idx(kr_list[0], indices_dict_kr), reversed_dict_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'j', 'e', 'o', 'l', 'l', 'a', 'n', 'a', 'm', '-', 'd', 'o', '<eos>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxlist_to_char(char_to_idx(en_list[0], indices_dict_en), reversed_dict_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(str_list, indices_dict, is_target = False):\n",
    "    result_list = []\n",
    "    result_list_targ = []\n",
    "    for string in str_list:\n",
    "        idx_list = char_to_idx(string, indices_dict)\n",
    "        if is_target:\n",
    "            nparr = np.array(idx_list[:-1])\n",
    "            result_list.append(idx_list[:-1])\n",
    "            result_list_targ.append(idx_list[1:])\n",
    "        else:\n",
    "            result_list.append(idx_list)\n",
    "    if is_target:\n",
    "        return result_list, result_list_targ\n",
    "    else:\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = generate_data(en_list, indices_dict_en)\n",
    "kr_data, kr_data_label = generate_data(kr_list, indices_dict_kr, is_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data_max = max(list(map(len, en_data)))\n",
    "en_data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kr_data_max = max(list(map(len, kr_data)))\n",
    "kr_data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_arr(idxlist, maxlen):\n",
    "    result = []\n",
    "    for item in idxlist:\n",
    "        arr = np.zeros(maxlen)\n",
    "        for i, sub in enumerate(item):\n",
    "            arr[i] = sub\n",
    "        result.append(arr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = get_padded_arr(en_data, en_data_max)\n",
    "kr_data = get_padded_arr(kr_data, kr_data_max)\n",
    "kr_data_label = get_padded_arr(kr_data_label, kr_data_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # For Shuffling\n",
    "random.seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(en_data, kr_data, kr_data_label)\n",
    "zipped_list = list(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(zipped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = []\n",
    "kr_data = []\n",
    "kr_data_label = []\n",
    "for tup in zipped_list:\n",
    "    en_data.append(tup[0])\n",
    "    kr_data.append(tup[1])\n",
    "    kr_data_label.append(tup[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionaries:\n",
    "with open(\"indices_kr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(indices_dict_kr, f)\n",
    "with open(\"indices_en.pkl\", \"wb\") as f:\n",
    "    pickle.dump(indices_dict_en, f)\n",
    "with open(\"rev_indices_kr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reversed_dict_kr, f)\n",
    "with open(\"rev_indices_en.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reversed_dict_en, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Train-Val)-Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 split. No test data, will test with just some examples\n",
    "x_en_train = en_data[0: round(len(en_data)*0.8)]\n",
    "x_en_test = en_data[round(len(en_data)*0.8) :]\n",
    "x_kr_train = kr_data[0: round(len(kr_data)*0.8)]\n",
    "x_kr_test = kr_data[round(len(kr_data)*0.8) : ]\n",
    "y_kr_train = kr_data_label[0: round(len(kr_data_label)*0.8)]\n",
    "y_kr_test = kr_data_label[round(len(kr_data_label)*0.8) : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_batches(data, n_batch):\n",
    "#     result = []\n",
    "#     data = data.copy()\n",
    "#     if len(data) % n_batch != 0:\n",
    "#         fill = n_batch - (len(data) % n_batch)\n",
    "#         fill_idxs = [random.randint(0, len(data)-1) for _ in range(fill)] # pick random integers to duplicate data\n",
    "#         for idx in fill_idxs:\n",
    "#             data.append(data[idx])\n",
    "#     for i in range(0, len(data), n_batch):\n",
    "#         result.append(data[i:i+n_batch])\n",
    "#     return tf.convert_to_tensor(result, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train dataset\n",
    "# x_en_train = generate_batches(x_en_train, 64)\n",
    "# x_kr_train = generate_batches(x_kr_train, 64)\n",
    "# y_kr_train = generate_batches(y_kr_train, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test dataset\n",
    "# x_en_test = tf.convert_to_tensor(x_en_test, dtype = tf.float32)\n",
    "# x_kr_test = tf.convert_to_tensor(x_kr_test, dtype = tf.float32)\n",
    "# y_kr_test = tf.convert_to_tensor(y_kr_test, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory management:\n",
    "Delete:\n",
    "- kr_list\n",
    "- en_list\n",
    "- zipped\n",
    "- en_data\n",
    "- kr_data\n",
    "- kr_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kr_list, en_list, zipped, en_data, kr_data, kr_data_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Code Acquired from Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding using the traditional Sinusoidal functions\n",
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding to be concatenated\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='relu')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Config\n",
    "num_layers = 4\n",
    "d_model = 256\n",
    "dff = 256\n",
    "num_heads = 4\n",
    "dropout_rate = 0.2\n",
    "vocab_size_kr = len(indices_dict_kr.keys()) - 2\n",
    "vocab_size_en = len(indices_dict_en.keys()) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=40000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 21:30:34.831291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 21:30:34.832872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:34.833031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:34.833085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:35.128429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:35.128542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:35.128597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 21:30:35.128652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13322 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "# optimizer = tf.keras.optimizers.Adam(0.01, beta_1=0.9, beta_2=0.98, epsilon=1e-9, clipvalue=0.5)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.experimental.RMSprop(learning_rate)\n",
    "# optimizer = tf.keras.optimizers.experimental.SGD(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(400000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True)#, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size= vocab_size_en,\n",
    "    target_vocab_size= vocab_size_kr,\n",
    "    dropout_rate=dropout_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "x_en_train = tf.convert_to_tensor(x_en_train, dtype = tf.float32)\n",
    "y_kr_train = tf.convert_to_tensor(y_kr_train, dtype = tf.float32)\n",
    "x_kr_train = tf.convert_to_tensor(x_kr_train, dtype = tf.float32)\n",
    "# Test dataset\n",
    "x_en_test = tf.convert_to_tensor(x_en_test, dtype = tf.float32)\n",
    "x_kr_test = tf.convert_to_tensor(x_kr_test, dtype = tf.float32)\n",
    "y_kr_test = tf.convert_to_tensor(y_kr_test, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices(((x_en_train, x_kr_train), y_kr_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 21:30:36.948853: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-12-12 21:30:37.044151: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    }
   ],
   "source": [
    "# So that it only knows the input shape\n",
    "output = transformer((x_en_train[0:1 , :], x_kr_train[0:1 , :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  4744960   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  8958720   \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  11051     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,714,731\n",
      "Trainable params: 13,714,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 15s 39ms/step - loss: 2.5209 - masked_accuracy: 0.0256 - val_loss: 1.5668 - val_masked_accuracy: 0.0914\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 1.3800 - masked_accuracy: 0.1847 - val_loss: 1.1023 - val_masked_accuracy: 0.3360\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 1.0652 - masked_accuracy: 0.3476 - val_loss: 0.9006 - val_masked_accuracy: 0.4509\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.9027 - masked_accuracy: 0.4431 - val_loss: 0.7760 - val_masked_accuracy: 0.5173\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.7854 - masked_accuracy: 0.5018 - val_loss: 0.6521 - val_masked_accuracy: 0.5829\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.6410 - masked_accuracy: 0.5859 - val_loss: 0.4107 - val_masked_accuracy: 0.7263\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.4531 - masked_accuracy: 0.7011 - val_loss: 0.2751 - val_masked_accuracy: 0.8227\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.3457 - masked_accuracy: 0.7760 - val_loss: 0.2035 - val_masked_accuracy: 0.8749\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.2692 - masked_accuracy: 0.8269 - val_loss: 0.1482 - val_masked_accuracy: 0.9099\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.2082 - masked_accuracy: 0.8662 - val_loss: 0.1253 - val_masked_accuracy: 0.9226\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.1693 - masked_accuracy: 0.8909 - val_loss: 0.0997 - val_masked_accuracy: 0.9413\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.1414 - masked_accuracy: 0.9094 - val_loss: 0.0888 - val_masked_accuracy: 0.9473\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.1220 - masked_accuracy: 0.9210 - val_loss: 0.0736 - val_masked_accuracy: 0.9577\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.1082 - masked_accuracy: 0.9312 - val_loss: 0.0713 - val_masked_accuracy: 0.9580\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0958 - masked_accuracy: 0.9398 - val_loss: 0.0604 - val_masked_accuracy: 0.9651\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0858 - masked_accuracy: 0.9461 - val_loss: 0.0573 - val_masked_accuracy: 0.9669\n",
      "Epoch 17/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0775 - masked_accuracy: 0.9516 - val_loss: 0.0547 - val_masked_accuracy: 0.9698\n",
      "Epoch 18/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0717 - masked_accuracy: 0.9549 - val_loss: 0.0489 - val_masked_accuracy: 0.9723\n",
      "Epoch 19/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0662 - masked_accuracy: 0.9576 - val_loss: 0.0466 - val_masked_accuracy: 0.9746\n",
      "Epoch 20/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0626 - masked_accuracy: 0.9608 - val_loss: 0.0448 - val_masked_accuracy: 0.9745\n",
      "Epoch 21/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0585 - masked_accuracy: 0.9630 - val_loss: 0.0421 - val_masked_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0537 - masked_accuracy: 0.9657 - val_loss: 0.0389 - val_masked_accuracy: 0.9784\n",
      "Epoch 23/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0504 - masked_accuracy: 0.9675 - val_loss: 0.0366 - val_masked_accuracy: 0.9789\n",
      "Epoch 24/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0484 - masked_accuracy: 0.9691 - val_loss: 0.0365 - val_masked_accuracy: 0.9786\n",
      "Epoch 25/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0459 - masked_accuracy: 0.9704 - val_loss: 0.0366 - val_masked_accuracy: 0.9774\n",
      "Epoch 26/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0434 - masked_accuracy: 0.9717 - val_loss: 0.0314 - val_masked_accuracy: 0.9820\n",
      "Epoch 27/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0395 - masked_accuracy: 0.9743 - val_loss: 0.0331 - val_masked_accuracy: 0.9808\n",
      "Epoch 28/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0384 - masked_accuracy: 0.9752 - val_loss: 0.0301 - val_masked_accuracy: 0.9824\n",
      "Epoch 29/100\n",
      "307/307 [==============================] - 10s 32ms/step - loss: 0.0364 - masked_accuracy: 0.9759 - val_loss: 0.0294 - val_masked_accuracy: 0.9819\n",
      "Epoch 30/100\n",
      "307/307 [==============================] - 10s 32ms/step - loss: 0.0346 - masked_accuracy: 0.9766 - val_loss: 0.0287 - val_masked_accuracy: 0.9830\n",
      "Epoch 31/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0326 - masked_accuracy: 0.9784 - val_loss: 0.0268 - val_masked_accuracy: 0.9843\n",
      "Epoch 32/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0308 - masked_accuracy: 0.9795 - val_loss: 0.0272 - val_masked_accuracy: 0.9830\n",
      "Epoch 33/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0301 - masked_accuracy: 0.9795 - val_loss: 0.0248 - val_masked_accuracy: 0.9855\n",
      "Epoch 34/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0291 - masked_accuracy: 0.9798 - val_loss: 0.0258 - val_masked_accuracy: 0.9837\n",
      "Epoch 35/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0276 - masked_accuracy: 0.9806 - val_loss: 0.0237 - val_masked_accuracy: 0.9852\n",
      "Epoch 36/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0264 - masked_accuracy: 0.9817 - val_loss: 0.0229 - val_masked_accuracy: 0.9854\n",
      "Epoch 37/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0257 - masked_accuracy: 0.9823 - val_loss: 0.0233 - val_masked_accuracy: 0.9853\n",
      "Epoch 38/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 0.0247 - masked_accuracy: 0.9828 - val_loss: 0.0218 - val_masked_accuracy: 0.9868\n",
      "Epoch 39/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0239 - masked_accuracy: 0.9835 - val_loss: 0.0242 - val_masked_accuracy: 0.9859\n",
      "Epoch 40/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0241 - masked_accuracy: 0.9834 - val_loss: 0.0240 - val_masked_accuracy: 0.9850\n",
      "Epoch 41/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0222 - masked_accuracy: 0.9848 - val_loss: 0.0199 - val_masked_accuracy: 0.9872\n",
      "Epoch 42/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0221 - masked_accuracy: 0.9844 - val_loss: 0.0206 - val_masked_accuracy: 0.9870\n",
      "Epoch 43/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0211 - masked_accuracy: 0.9853 - val_loss: 0.0209 - val_masked_accuracy: 0.9871\n",
      "Epoch 44/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 0.0201 - masked_accuracy: 0.9861 - val_loss: 0.0186 - val_masked_accuracy: 0.9888\n",
      "Epoch 45/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0206 - masked_accuracy: 0.9853 - val_loss: 0.0185 - val_masked_accuracy: 0.9887\n",
      "Epoch 46/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0194 - masked_accuracy: 0.9864 - val_loss: 0.0182 - val_masked_accuracy: 0.9894\n",
      "Epoch 47/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0190 - masked_accuracy: 0.9866 - val_loss: 0.0201 - val_masked_accuracy: 0.9877\n",
      "Epoch 48/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0191 - masked_accuracy: 0.9865 - val_loss: 0.0206 - val_masked_accuracy: 0.9875\n",
      "Epoch 49/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0178 - masked_accuracy: 0.9873 - val_loss: 0.0211 - val_masked_accuracy: 0.9885\n",
      "Epoch 50/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0177 - masked_accuracy: 0.9873 - val_loss: 0.0207 - val_masked_accuracy: 0.9877\n",
      "Epoch 51/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0180 - masked_accuracy: 0.9870 - val_loss: 0.0177 - val_masked_accuracy: 0.9893\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0168 - masked_accuracy: 0.9880 - val_loss: 0.0177 - val_masked_accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "307/307 [==============================] - 11s 37ms/step - loss: 0.0165 - masked_accuracy: 0.9882 - val_loss: 0.0177 - val_masked_accuracy: 0.9905\n",
      "Epoch 54/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0165 - masked_accuracy: 0.9884 - val_loss: 0.0195 - val_masked_accuracy: 0.9881\n",
      "Epoch 55/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0164 - masked_accuracy: 0.9885 - val_loss: 0.0174 - val_masked_accuracy: 0.9898\n",
      "Epoch 56/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0162 - masked_accuracy: 0.9881 - val_loss: 0.0173 - val_masked_accuracy: 0.9903\n",
      "Epoch 57/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0157 - masked_accuracy: 0.9889 - val_loss: 0.0206 - val_masked_accuracy: 0.9878\n",
      "Epoch 58/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0161 - masked_accuracy: 0.9885 - val_loss: 0.0190 - val_masked_accuracy: 0.9897\n",
      "Epoch 59/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0155 - masked_accuracy: 0.9890 - val_loss: 0.0164 - val_masked_accuracy: 0.9911\n",
      "Epoch 60/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0149 - masked_accuracy: 0.9891 - val_loss: 0.0195 - val_masked_accuracy: 0.9889\n",
      "Epoch 61/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0155 - masked_accuracy: 0.9890 - val_loss: 0.0199 - val_masked_accuracy: 0.9884\n",
      "Epoch 62/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0156 - masked_accuracy: 0.9891 - val_loss: 0.0194 - val_masked_accuracy: 0.9894\n",
      "Epoch 63/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0146 - masked_accuracy: 0.9895 - val_loss: 0.0198 - val_masked_accuracy: 0.9887\n",
      "Epoch 64/100\n",
      "307/307 [==============================] - 11s 34ms/step - loss: 0.0151 - masked_accuracy: 0.9892 - val_loss: 0.0184 - val_masked_accuracy: 0.9898\n",
      "Epoch 65/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0154 - masked_accuracy: 0.9893 - val_loss: 0.0168 - val_masked_accuracy: 0.9902\n",
      "Epoch 66/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0137 - masked_accuracy: 0.9904 - val_loss: 0.0159 - val_masked_accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0143 - masked_accuracy: 0.9900 - val_loss: 0.0166 - val_masked_accuracy: 0.9898\n",
      "Epoch 68/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0143 - masked_accuracy: 0.9898 - val_loss: 0.0166 - val_masked_accuracy: 0.9907\n",
      "Epoch 69/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0135 - masked_accuracy: 0.9905 - val_loss: 0.0168 - val_masked_accuracy: 0.9900\n",
      "Epoch 70/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0137 - masked_accuracy: 0.9904 - val_loss: 0.0184 - val_masked_accuracy: 0.9899\n",
      "Epoch 71/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0138 - masked_accuracy: 0.9898 - val_loss: 0.0185 - val_masked_accuracy: 0.9902\n",
      "Epoch 72/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0140 - masked_accuracy: 0.9901 - val_loss: 0.0178 - val_masked_accuracy: 0.9902\n",
      "Epoch 73/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0136 - masked_accuracy: 0.9905 - val_loss: 0.0200 - val_masked_accuracy: 0.9899\n",
      "Epoch 74/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0137 - masked_accuracy: 0.9904 - val_loss: 0.0168 - val_masked_accuracy: 0.9911\n",
      "Epoch 75/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0125 - masked_accuracy: 0.9911 - val_loss: 0.0155 - val_masked_accuracy: 0.9916\n",
      "Epoch 76/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0134 - masked_accuracy: 0.9907 - val_loss: 0.0157 - val_masked_accuracy: 0.9915\n",
      "Epoch 77/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0139 - masked_accuracy: 0.9901 - val_loss: 0.0191 - val_masked_accuracy: 0.9898\n",
      "Epoch 78/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0137 - masked_accuracy: 0.9905 - val_loss: 0.0168 - val_masked_accuracy: 0.9907\n",
      "Epoch 79/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0130 - masked_accuracy: 0.9908 - val_loss: 0.0175 - val_masked_accuracy: 0.9901\n",
      "Epoch 80/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0130 - masked_accuracy: 0.9909 - val_loss: 0.0178 - val_masked_accuracy: 0.9901\n",
      "Epoch 81/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0137 - masked_accuracy: 0.9901 - val_loss: 0.0169 - val_masked_accuracy: 0.9911\n",
      "Epoch 82/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0127 - masked_accuracy: 0.9910 - val_loss: 0.0160 - val_masked_accuracy: 0.9910\n",
      "Epoch 83/100\n",
      "307/307 [==============================] - 11s 36ms/step - loss: 0.0137 - masked_accuracy: 0.9902 - val_loss: 0.0166 - val_masked_accuracy: 0.9909\n",
      "Epoch 84/100\n",
      "307/307 [==============================] - 11s 37ms/step - loss: 0.0132 - masked_accuracy: 0.9909 - val_loss: 0.0175 - val_masked_accuracy: 0.9908\n",
      "Epoch 85/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0129 - masked_accuracy: 0.9908 - val_loss: 0.0164 - val_masked_accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "307/307 [==============================] - 10s 32ms/step - loss: 0.0131 - masked_accuracy: 0.9909 - val_loss: 0.0183 - val_masked_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0134 - masked_accuracy: 0.9906 - val_loss: 0.0183 - val_masked_accuracy: 0.9902\n",
      "Epoch 88/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0131 - masked_accuracy: 0.9907 - val_loss: 0.0175 - val_masked_accuracy: 0.9902\n",
      "Epoch 89/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0126 - masked_accuracy: 0.9911 - val_loss: 0.0174 - val_masked_accuracy: 0.9902\n",
      "Epoch 90/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0130 - masked_accuracy: 0.9909 - val_loss: 0.0172 - val_masked_accuracy: 0.9916\n",
      "Epoch 91/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0129 - masked_accuracy: 0.9910 - val_loss: 0.0174 - val_masked_accuracy: 0.9906\n",
      "Epoch 92/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 0.0143 - masked_accuracy: 0.9903 - val_loss: 0.0166 - val_masked_accuracy: 0.9910\n",
      "Epoch 93/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0127 - masked_accuracy: 0.9911 - val_loss: 0.0176 - val_masked_accuracy: 0.9909\n",
      "Epoch 94/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 0.0123 - masked_accuracy: 0.9913 - val_loss: 0.0174 - val_masked_accuracy: 0.9911\n",
      "Epoch 95/100\n",
      "307/307 [==============================] - 10s 32ms/step - loss: 0.0126 - masked_accuracy: 0.9910 - val_loss: 0.0164 - val_masked_accuracy: 0.9911\n",
      "Epoch 96/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0129 - masked_accuracy: 0.9909 - val_loss: 0.0146 - val_masked_accuracy: 0.9920\n",
      "Epoch 97/100\n",
      "307/307 [==============================] - 11s 35ms/step - loss: 0.0121 - masked_accuracy: 0.9913 - val_loss: 0.0158 - val_masked_accuracy: 0.9913\n",
      "Epoch 98/100\n",
      "307/307 [==============================] - 10s 33ms/step - loss: 0.0136 - masked_accuracy: 0.9905 - val_loss: 0.0147 - val_masked_accuracy: 0.9918\n",
      "Epoch 99/100\n",
      "307/307 [==============================] - 10s 34ms/step - loss: 0.0130 - masked_accuracy: 0.9911 - val_loss: 0.0160 - val_masked_accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "307/307 [==============================] - 11s 37ms/step - loss: 0.0133 - masked_accuracy: 0.9906 - val_loss: 0.0162 - val_masked_accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90bc5cbb80>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "ds = train.batch(batch_size, drop_remainder=True)\n",
    "# transformer.fit(x = (x_en_train, x_kr_train), y= y_kr_train,\n",
    "transformer.fit(x = ds,\n",
    "#                 batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data = ((x_en_test, x_kr_test), y_kr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_main(model, indices_dict, reversed_dict, string):\n",
    "    output_list = []\n",
    "    idx_list = []\n",
    "    string = char_to_idx(string, indices_dict)\n",
    "    string = get_padded_arr([string], en_data_max)\n",
    "    string = tf.convert_to_tensor(string, dtype=tf.float32)\n",
    "    output = tf.constant(1, dtype=tf.float32, shape=(1, 1)) # value = 1 => \"<sos>\"\n",
    "    counter = 0 # For safety\n",
    "    while True:\n",
    "        if counter > 100:\n",
    "            print(\"Something went wrong with the input\")\n",
    "            break\n",
    "        prediction = transformer([string, output], training=False)\n",
    "        ind_predicted = np.argmax(prediction[:, -1, :]) # Always capture the last prediction's argmax. \n",
    "        if ind_predicted == 2: # 2 is \"<eos>\"\n",
    "            return join_jamos(output_list)\n",
    "        else:\n",
    "            output_list.append(reversed_dict[ind_predicted])\n",
    "            idx_list.append(ind_predicted)\n",
    "            output = tf.expand_dims(tf.convert_to_tensor(idx_list, dtype=tf.float32), 0)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "translate_kr_en = partial(translate_main, transformer, indices_dict_en, reversed_dict_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하준'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_kr_en(\"hajun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = [\"hajun\", \"jeon-hye-woong\", \"haeangil\", \"apeum\", \"gangnam\", \"africa\", \"aprica\", \"papri-ka\", \"seocho\", \"galwolilgil\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하준\n",
      "전혜고원\n",
      "해안길\n",
      "아픔\n",
      "강남\n",
      "아리리차\n",
      "압리차\n",
      "팝리가\n",
      "서초\n",
      "갈월릴길\n"
     ]
    }
   ],
   "source": [
    "for token in testing:\n",
    "    print(translate_kr_en(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "266608b04208d70543cb49c8748fa82829af85a97fbaee1332ca8e44492d567f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
