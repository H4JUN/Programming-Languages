{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as r\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape English and Korean addresses\n",
    "- The website used is jusoga.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.jusoga.com\"\n",
    "response = r.get(url)\n",
    "response.status_code\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces_tags = soup.find_all(\"a\", {\"href\" : re.compile(r'jusoga\\.com/')})\n",
    "province = [provinces.text for provinces in provinces_tags[:-1]] # Last item is not province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_tags = []\n",
    "for name in province:\n",
    "    new_path = f\"{url}/{name}\"\n",
    "    response = r.get(new_path)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        city_tags = soup.find_all(\"a\", {\"href\" : re.compile(name)}) \n",
    "        cities_tags.extend(city_tags[:-1])\n",
    "# get urls of each city\n",
    "cities_urls = [url.get(\"href\") for url in cities_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_tags = []\n",
    "for url in cities_urls:\n",
    "    response = r.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        region_tags = soup.find_all(\"a\", {\"href\" : re.compile(url)}) \n",
    "        regions_tags.extend(region_tags[:-1])\n",
    "# get urls of each region\n",
    "regions_urls = [url.get(\"href\") for url in regions_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"url_jusoga\", \"wb\") as f:\n",
    "    pickle.dump(regions_urls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"url_jusoga\", \"rb\") as f:\n",
    "    regions_urls = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions_urls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "- Refer to `webscraping.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "- English pairs are reversed in order\n",
    "- Create a dictionary in which the keys are the korean address token and the values is the corresponding English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process English tokens:\n",
    "# Assume the first word is always the address number to remove\n",
    "def preprocess_en(address):\n",
    "    splitted = [word.strip() for word in address.split(',')]\n",
    "    splitted = splitted[1:]\n",
    "    return splitted[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_en('310-2, 3·15-daero, Masanhappo-gu, Changwon-si, Gyeongsangnam-do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Korean tokens:\n",
    "# Remove whatever is inside the parentheses, and remove the numbers)\n",
    "def preprocess_kr(address):\n",
    "    substituted = re.sub(r'\\(.+\\)', '', address)\n",
    "    substituted = re.sub(r'지하 ', '', substituted)\n",
    "    substituted = re.sub(r'광역시', '', substituted) # Remove 광역시 as it is not implemented in English\n",
    "    substituted = re.sub(r'특별시', '', substituted) # Remove 특별시 as it is not implemented in English\n",
    "    substituted = re.sub(r'특별자치', '', substituted) # Remove [제주|세종]특별자치[시|도]as it is sejong-si and jeju-do in English\n",
    "    # print(substituted)\n",
    "    splitted = substituted.strip().split(' ')\n",
    "    splitted = [word.strip() for word in splitted]\n",
    "    return splitted[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_kr('경기도 과천시 별양로 지하 177 (별양동)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dict(list_of_pairs):\n",
    "    result = {}\n",
    "    for pair in list_of_pairs:\n",
    "        kor_addr, en_addr = pair\n",
    "        pp_kor_addr = preprocess_kr(kor_addr)\n",
    "        pp_en_addr = preprocess_en(en_addr)\n",
    "        assert(len(pp_kor_addr) == len(pp_en_addr))\n",
    "        for i in range(len(pp_kor_addr)):\n",
    "            result[pp_kor_addr[i]] = pp_en_addr[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = generate_dict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change of plan: Remove the keys that have numbers in it. Readd them to the dictionary\n",
    "remove_list = [key for key in result_dict.keys() if any(char.isdigit() for char in key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_and_append(addr, result_dict):\n",
    "    subsituted_kr = re.sub('[0-9]+.*', '', addr).strip()\n",
    "    splitted_en = result_dict[addr].split()[0].strip()\n",
    "    result_dict[subsituted_kr] = splitted_en\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(remove_list)):\n",
    "    edit_and_append(remove_list[i], result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the old keys\n",
    "for i in range(len(remove_list)):\n",
    "    del result_dict[remove_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_dict.pkl\", \"rb\") as f:\n",
    "    result_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Data\n",
    "with open(\"/home/tyson/Private/Confirmed/coding/romanization/kor_list.pkl\", \"rb\") as f:\n",
    "    kor_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/tyson/Private/Confirmed/coding/romanization/eng_list.pkl\", \"rb\") as f:\n",
    "    eng_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_list_pro = []\n",
    "for item in kor_list:\n",
    "    new = re.sub(r'특별자치', '', item)\n",
    "    new = re.sub(r'특별시|광역시', '', new)\n",
    "    kor_list_pro.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(kor_list_pro) == len(eng_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict2 = {}\n",
    "for i in range(len(kor_list_pro)):\n",
    "    result_dict2[kor_list_pro[i]] = eng_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict2.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the two dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_final = result_dict | result_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_dict_final.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in result_dict_final.keys():\n",
    "    for char in key:\n",
    "        if 65 <= ord(char) <= 122:\n",
    "            print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in result_dict_final.keys():\n",
    "    for char in key:\n",
    "        if 0 <= ord(char) <= 64:\n",
    "            print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result_dict_final[\"APEC로\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(result_dict_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_dict.pkl\", \"rb\") as f:\n",
    "    result_dict_final = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in result_dict_final.keys():\n",
    "    for char in key:\n",
    "        if 65 <= ord(char) <= 122:\n",
    "            print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "266608b04208d70543cb49c8748fa82829af85a97fbaee1332ca8e44492d567f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
